{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than using a camera to take images, there are many medical devices that can acquire images useful for the detection and diagnosis of diseases.\n",
    "\n",
    "These can be 2D (X-ray) or 3D (MRI). On this course, we will focus on images from **M**agnetic **R**esonance **I**maging (**MRI**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sdbif.org/index/wp-content/uploads/2020/02/Head_Scans2.jpg\" alt=\"Drawing\" align=\"middle\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same pixel (or voxel) information discussed in previous notebooks to visualise biological properties in living people. \n",
    "\n",
    "In order to visualise our images, first we need to transfer them from the scanner to our computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the scanner to our computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuroimaging file formats\n",
    "\n",
    "|Format Name | File Extension | Origin |\n",
    "|---|---|---|\n",
    "| DICOM | none | ACR/NEMA Consortium |\n",
    "| Analyze | .img/.hdr | Analyze Software, Mayo Clinic |\n",
    "| NIfTI | .nii | Neuroimaging Informatics Technology Initiative |\n",
    "| MINC | .mnc | Montreal Neurological Institute |\n",
    "| NRRD | .nrrd | |\n",
    "\n",
    "From the MRI scanner, images are initially collected in the DICOM format and can be converted to these other formats to make working with the data easier.\n",
    "\n",
    "<img src=\"../fig/dicom_to_nifti.png\" alt=\"Drawing\" align=\"middle\" width=\"600px\"/>\n",
    "\n",
    "Let's download some example DICOM data to see what it looks like.\n",
    "This data was generously shared publicly by the [Princeton Handbook for Reproducible Neuroimaging](https://brainhack-princeton.github.io/handbook/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use commands from the UNIX terminal in a jupyter notebook by putting `%%bash` at the top of a code cell.\n",
    "Lets use a UNIX terminal command to list files in the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets use the UNIX terminal to download some DICOM data from the internet. See comments in the code block below that explains each command.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Download the DICOM data using the wget command\n",
    "wget https://zenodo.org/record/3677090/files/0219191_mystudy-0219-1114.tar.gz -O ../data/0219191_mystudy-0219-1114.tar.gz\n",
    "\n",
    "# Make a new directory for the DICOM data using the mkdir command\n",
    "mkdir -p ../data/dicom_examples\n",
    "\n",
    "# Unzip the DICOM data into this new directory using the tar command\n",
    "tar -xvzf ../data/0219191_mystudy-0219-1114.tar.gz -C ../data/dicom_examples\n",
    "\n",
    "# Compress each DICOM file using the gzip command\n",
    "gzip -d ../data/dicom_examples/0219191_mystudy-0219-1114/dcm/*dcm.gz\n",
    "\n",
    "# Clean up by deleting the original file we downloaded using the rm command\n",
    "rm ../data/0219191_mystudy-0219-1114.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NIfTI is one of the most ubiquitous file formats for storing neuroimaging data.\n",
    "If you're interested in learning more about NIfTI images, we highly recommend [this blog post about the NIfTI format](http://brainder.org/2012/09/23/the-nifti-file-format/).\n",
    "We can convert our DICOM data to NIfTI using [dcm2niix](https://github.com/rordenlab/dcm2niix).\n",
    "\n",
    "We can learn how to run `dcm2niix` by taking a look at its help menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "dcm2niix -help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting DICOM to NIfTI\n",
    "When converting DICOM files to NIfTI format, we often want to:\n",
    "1. Output the NIfTI files into a new folder to separate them from DICOMs.\n",
    "2. Compress the NIfTI files to save space.\n",
    "\n",
    "Can you use the `dcm2niix` command to convert the DICOMS we downloaded into NIfTI format? Use commands from the `%%bash` cells and the `dcm2niix` help information above to help you.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "<b>EXERCISE:</b> Convert the Princeton DICOM data to NIfTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p ../data/dicom_examples/nii\n",
    "dcm2niix \\\n",
    "    -z y \\\n",
    "    -o ../data/dicom_examples/nii \\\n",
    "    ../data/dicom_examples/0219191_mystudy-0219-1114/dcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading NIfTI images\n",
    "\n",
    "There are 3 key parts to a NIfTI image:\n",
    "1. The Header\n",
    "2. The Data\n",
    "3. The Affine\n",
    "\n",
    "We will explore these below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[NiBabel](http://nipy.org/nibabel/) is a Python package for reading and writing neuroimaging data. To learn more about how NiBabel handles NIfTIs, check out the [Working with NIfTI images](http://nipy.org/nibabel/nifti_images.html) page of the NiBabel documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, use the `load()` function to create a NiBabel image object from a NIfTI file. We'll load in an example T1w image from the zip file we just downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_img = nib.load(\"../data/dicom_examples/nii/dcm_anat_ses-01_T1w_20190219111436_5.nii.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. [Header](http://nipy.org/nibabel/nibabel_images.html#the-image-header): contains metadata about the image, such as image dimensions, data type, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_hdr = t1_img.header\n",
    "print(t1_hdr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`t1_hdr` is a Python **dictionary**. Dictionaries are containers that hold pairs of objects - keys and values. Let's take a look at all of the keys.\n",
    "Similar to `t1_img` in which attributes can be accessed by typing `t1_img.` and hitting <kbd>Tab</kbd>, you can do the same with `t1_hdr`. In particular, we'll be using a **method** belonging to `t1_hdr` that will allow you to view the keys associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_hdr.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that **methods** require you to include `()` at the end of them whereas **attributes** do not.\n",
    "The key difference between a method and an attribute is:\n",
    "- Attributes are *stored values* kept within an object\n",
    "- Methods are *processes* that we can run using the object. Usually a method takes attributes, performs an operation on them, then returns it for you to use.\n",
    "\n",
    "When you type in `t1_img.` followed by <kbd>Tab</kbd>, you'll see that attributes are highlighted in <span style=\"color:orange\"> orange </span> and methods highlighted in <span style=\"color:blue\"> blue </span>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above is a list of **keys** you can use from `t1_hdr` to access **values**. We can access the value stored by a given key by typing:\n",
    "\n",
    "```python\n",
    "t1_hdr['<key_name>']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>EXERCISE:</b> Extract the value of <code>pixdim</code> from <code>t1_hdr</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_hdr['pixdim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to metadata embedded in the NIfTI header, the T1w image also has a corresponding JSON file with additional scan acquisition details. Using the JSON file to store this information is a concept added by BIDS (which we'll cover in the next lesson) to log the important bits of information that traditionally get excluded from the NIfTI header.\n",
    "\n",
    "Let's take a look at it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/dicom_examples/nii/dcm_anat_ses-01_T1w_20190219111436_5.json\", \"r\") as f:\n",
    "    t1_metadata = json.load(f)\n",
    "\n",
    "t1_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The additional metadata are also in the form of a Python <b>dictionary</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>EXERCISE:</b> Extract the value of <code>SliceThickness</code> from <code>t1_metadata</code> similar to how you did previously for <code>t1_hdr</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_metadata[\"SliceThickness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data\n",
    "As you've seen above, the header contains useful information that gives us information about the properties (metadata) associated with the MR data we've loaded in. Now we'll move in to loading the actual *image data itself*. We can achieve this by using the *method* called `t1_img.get_fdata()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_data = t1_img.get_fdata()\n",
    "t1_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What type of data is this exactly? We can determine this by calling the `type()` function on `t1_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(t1_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is a multidimensional **array** representing the image data. In Python, an array is used to store lists of numerical data into something like a table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>EXERCISE:</b> Let's check out some *attributes* of the array. How can we see the number of dimensions in the <code>t1_data</code> array? What about the how big each dimension is (shape)? Once again, all of the attributes of the array can be seen by typing `t1_data.` and <kbd>Tab</kbd>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_data.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`t1_data` contains 3 dimensions. You can think of the data as a 3D version of a picture (more accurately, a volume).\n",
    "\n",
    "<img src=\"../fig/numpy_arrays.png\" alt=\"Drawing\" align=\"middle\" width=\"600px\"/>\n",
    "\n",
    "While typical 2D pictures are made out of squares called **pixels**, a 3D MR image is made up of 3D cubes called **voxels**.\n",
    "\n",
    "<img src=\"http://www.sprawls.org/mripmt/MRI10/MR10-2.jpg\" alt=\"Drawing\" align=\"middle\" width=\"500px\"/>\n",
    "\n",
    "**Note:** MRI can be acquired in any orientation, so thickness above may relate to another dimension!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3 numbers given here represent the number of values *along a respective dimension (x,y,z)*. This brain was scanned in 192 slices with a resolution of 256 x 256 voxels per slice. That means there are:\n",
    "\n",
    "$$x * y * z = value$$\n",
    "$$ 192 * 256 * 256 = 12582912$$ voxels in total!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the type of data inside of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_data.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that each element in the array (or voxel) is a floating-point number.   \n",
    "The data type of an image controls the range of possible intensities. As the number of possible values increases, the amount of space the image takes up in memory also increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "print(np.min(t1_data))\n",
    "print(np.max(t1_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our data, the range of intensity values goes from 0 (black) to more positive digits (whiter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we examine what value a particular voxel is? We can inspect the value of a voxel by selecting an **index** as follows:\n",
    "\n",
    "~~~python\n",
    "data[x,y,z]\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for example we can inspect a voxel at coordinates (10,20,3) by doing the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_data[9, 19, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Python uses **zero-based indexing**. The first item in the array is item 0. The second item is item 1, the third is item 2, etc.\n",
    "\n",
    "This yields a single value representing the intensity of the signal at a particular voxel! Next we'll see how to not just pull one voxel but a slice or an *array* of voxels for visualization and analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working With Image Data\n",
    "\n",
    "Slicing does exactly what it seems to imply. Giving our 3D volume, we pull out a 2D slice of our data. Here's an example of slicing from left to right (**sagittal slicing**):\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/5/56/Parasagittal_MRI_of_human_head_in_patient_with_benign_familial_macrocephaly_prior_to_brain_injury_%28ANIMATED%29.gif\"/>\n",
    "\n",
    "This gif is a series of 2D images or **slices** moving from left to right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pull the 50th slice in the x axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_slice = t1_data[49, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is similar to the indexing we did before to pull out a single voxel. However, instead of providing a value for each axis, the `:` indicates that we want to grab *all* values from that particular axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>EXERCISE:</b> Now try selecting the 80th slice from the y axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_slice = t1_data[:, 79, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>EXERCISE:</b> Finally try grabbing the 100th slice from the z axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_slice = t1_data[:, :, 99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've been slicing and dicing brain images but we have no idea what they look like! In the next section we'll show you how you can visualize brain slices!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing\n",
    "\n",
    "We previously inspected the signal intensity of the voxel at coordinates (10,20,3). Let's see what out data looks like when we slice it at this location. We've already indexed the data at each x, y, and z axis. Let's use `matplotlib`, Python's standard plotting library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "slices = [x_slice, y_slice, z_slice]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(slices), figsize=(15,15))\n",
    "for i, slice in enumerate(slices):\n",
    "    axes[i].imshow(slice.T, cmap=\"gray\", origin=\"lower\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An upgrade from `matplotlib` is `nilearn`, which provides several advanced plotting features for neuroimaging data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "\n",
    "plotting.view_img(t1_img, black_bg=True, colorbar=False, cmap=\"gray\", symmetric_cmap=False, vmin=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try dragging your mouse to view the MRI data interactively!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to step away from discussing our data and briefly mention the final important attribute of a NIfTI.\n",
    "\n",
    "### 3. [Affine](http://nipy.org/nibabel/coordinate_systems.html): tells the position of the image array data in a *reference space*\n",
    "\n",
    "The final important piece of metadata associated with an image file is the **affine matrix**. Below is the affine matrix for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_affine = t1_img.affine\n",
    "t1_affine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The affine matrix allows us to move between voxel coordinates (x,y,z) and world space coordinates (left/right,bottom/top,back/front). This allows us to understand how the image relates to how someone lay in the MRI scanner and contains important orientation information.\n",
    "\n",
    "Don't worry if this doesn't make sense right now, we will cover this in more detail in later notebooks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
