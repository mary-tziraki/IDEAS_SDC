{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRI Modalities\n",
    "\n",
    "MRI is versatile. Tuning the MRI scanner in different ways allows us to generate images that are sensitive to varying underlying biological properties. This is done by creating contrast between tissue types.\n",
    "\n",
    "## Image Contrast\n",
    "\n",
    "MRI scans are acquired using a combination of magnetic fields and radiofrequency pulses. While inside the magnetic field in the scanner, radiofrequency pulses transmit energy to tissues within the brain. These tissues then emit energy differently depending on unique tissue properties and produce different signal intensities. These varying signal intensities in the MR image create a contrast. This contrast allows us to distinguish between different tissue types. \n",
    "\n",
    "See this short [video](https://www.youtube.com/watch?v=1CGzk-nV06g) for a visual explanation.\n",
    "\n",
    "Various contrasts can be created by tuning the MRI scanner in different ways using **MRI sequences**. Different MRI sequences provide unique information regarding the underlying biological properties. We often call these **MRI modalities**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from nilearn import plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T1-weighted and T2-weighted MRI\n",
    "\n",
    "The time taken for energy to be emitted is called **relaxation time**. This can be broadly broken down into two types:\n",
    "\n",
    "### T1 relaxation\n",
    "The longitudinal relaxation time (T1) is the time taken for protons in the tissue to emit energy while realigning with the main magnetic field.  \n",
    "\n",
    "### T2 relaxation\n",
    "The transverse relaxation time (T2) is the time taken for protons in the tissue to emit energy while losing coherence (i.e. moving out of time with each other).\n",
    "\n",
    "|                | T1 (ms)      | T2 (ms)     |\n",
    "| :-------------: | :----------: | :-----------: |\n",
    "|  Bones | 500   | 50    |\n",
    "|  CSF | 4000   | 500    |\n",
    "|  Grey Matter | 1300   | 110    |\n",
    "|  White Matter   | 800 | 80 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tissue Relaxation Properties Create Image Contrast\n",
    "\n",
    "MRI sequences can be *weighted* towards T1 or T2 relaxation properties to produce unique image contrasts. We often abbreviate this to T1w or T2w images.\n",
    "\n",
    "The graphs below show how brain tissues have different relaxation properties. \n",
    "\n",
    "Tissues with faster relaxation properties have higher signal in T1w images. Tissues with slower relaxation properties have lower signal in T1w images. The reverse is true in T2w images.\n",
    "\n",
    "Higher signal relates to brighter voxels in an image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../fig/relaxations.png\" alt=\"Drawing\" align=\"middle\" width=\"1000px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you tell which tissue type would be brightest and darkest on a T1-weighted and T2-weighted image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a complex topic that we cannot cover in detail here. If you would like more detail, this [review article](https://pmj.bmj.com/content/89/1050/209) is a good place to start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising T1w and T2w Images\n",
    "\n",
    "With our new understanding of image contrasts, lets visualise this!\n",
    "\n",
    "Lets use a dataset we have already downloaded:\n",
    "\n",
    "- [Craving dataset](https://openneuro.org/datasets/ds003242/versions/1.0.0): Cue Induced Craving task following food fasting, social isolation and baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first state the directory we have downloaded the data in\n",
    "local_data_dir = '../data/'\n",
    "\n",
    "# create filename variables - this helps make the commands in the next cell easier to read\n",
    "T1_filename = local_data_dir + 'modalities_examples/craving_sub-SAXSISO01b_T1w.nii.gz'\n",
    "T2_filename = local_data_dir + 'modalities_examples/craving_sub-SAXSISO01b_T2w.nii.gz'      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read T1w and T2w anatomical images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets load the images using nibabel (see previous episode)\n",
    "T1_img = nib.load(T1_filename)\n",
    "T2_img = nib.load(T2_filename)\n",
    "\n",
    "# grab data array\n",
    "T1_data = T1_img.get_fdata()\n",
    "T2_data = T2_img.get_fdata()\n",
    "\n",
    "# print basic information of images\n",
    "print('T1 image path: {},\\n\\timage shape: {}'.format(T1_filename, T1_img.shape))\n",
    "print('\\tintensity value range: min: {:3.2f}, max: {:3.2f}'.format(np.min(T1_data.ravel()),np.max(T1_data.ravel())))\n",
    "print('\\nT2 image path: {},\\n\\timage shape: {}'.format(T2_filename, T2_img.shape))\n",
    "print('\\tintensity value range: min: {:3.2f}, max: {:3.2f}'.format(np.min(T2_data.ravel()),np.max(T2_data.ravel())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize T1w and T2w Images\n",
    "\n",
    "Nilearn is a useful package for visualising MRI data using python.\n",
    "\n",
    "The cell below plots a single slice from three views: Coronal, Sagittal, Axial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(20,10))\n",
    "plotting.plot_anat(T1_filename, title=\"T1\", vmax=500, axes=ax1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you plot the T2w image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax2 = plt.subplots(figsize=(20,10))\n",
    "plotting.plot_anat(T2_filename, title=\"T2\", vmax=300, axes=ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the signal intensities in the T1w and T2w images agree with the plots of their relaxation properties above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Using what you learned in the last session. Can you view the T1w or T2w images interactively using another command from the `nilearn` module?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotting.view_img(T1_filename, black_bg=True, colorbar=False, cmap=\"gray\", symmetric_cmap=False, vmin=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diffusion MRI\n",
    "\n",
    "Diffusion MRI is sensitive to the movement of water in the brain. The movement of water in the brain is highly directional. This means it is more likely to move along the connections between brain areas. \n",
    "\n",
    "We can use this information to build an image of what the connections in our brain looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have already downloaded some diffusion MRI data for you\n",
    "hardi_fname = local_data_dir + 'dmri_examples/HARDI150.nii.gz'\n",
    "hardi_bval_fname = local_data_dir + 'dmri_examples/HARDI150.bval'\n",
    "hardi_bvec_fname = local_data_dir + 'dmri_examples/HARDI150.bvec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "hardi_img = nib.load(hardi_fname)\n",
    "bvals = np.loadtxt(hardi_bval_fname)\n",
    "bvecs = np.loadtxt(hardi_bvec_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the shape of the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hardi_data = hardi_img.get_fdata()\n",
    "hardi_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diffusion MRI data is 4-dimensional. A 3D image (81, 106, 76) is acquired many times with sensitivities to the diffusion of water in different directions.\n",
    "\n",
    "Lets visualise some of these directions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets pick an axial slice in the middle\n",
    "ax_slice = hardi_data.shape[2] // 2;\n",
    "print('Middle axial slice is:', ax_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise various directions from raw diffusion MRI data\n",
    "\n",
    "# set up figure\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "# plot first direction \n",
    "# (the first direction is often b=0 and is not sensitive to a particular direction of water diffusion)\n",
    "plt.subplot(1, 4, 1).set_axis_off()\n",
    "plt.imshow(hardi_data[:,:,ax_slice,0], cmap='gray')\n",
    "plt.title(\"b=0\")\n",
    "\n",
    "# plot another direction\n",
    "plt.subplot(1, 4, 2).set_axis_off()\n",
    "plt.imshow(hardi_data[:,:,ax_slice,10], cmap='gray')\n",
    "plt.title(\"11th Direction\")\n",
    "\n",
    "# plot another direction\n",
    "plt.subplot(1, 4, 3).set_axis_off()\n",
    "plt.imshow(hardi_data[:,:,ax_slice,50], cmap='gray')\n",
    "plt.title(\"51st Direction\")\n",
    "\n",
    "# plot another direction\n",
    "plt.subplot(1, 4, 4).set_axis_off()\n",
    "plt.imshow(hardi_data[:,:,ax_slice,150], cmap='gray')\n",
    "plt.title(\"150th Direction\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXERCISE HERE TO REPRODUCE ABOVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diffusion MRI data needs to be processed before we can visualise properties associated with underlying biology.\n",
    "\n",
    "We won't go into this here, but check out the [DIPY examples](https://dipy.org/documentation/1.5.0/examples_built/reconst_dti/#example-reconst-dti) or the [diffusion MRI software carpentry course](https://carpentries-incubator.github.io/SDC-BIDS-dMRI/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two main measures we can extract after processing diffusion MRI data are:\n",
    "1. **Fractional Anisotropy (FA):** Higher values indicate diffusion of water is more directional (e.g. along connections in the white matter).\n",
    "2. **Mean Diffusivity (MD):** Higher values indicate an overall increase in diffusion (e.g. in free diffusing water in the cerebrospinal fluid surrounding the brain).\n",
    "\n",
    "We've created these maps for you. Try loading them using `nibabel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load FA and get data\n",
    "fa_img = nib.load('../data/dmri_examples/FA.nii.gz')\n",
    "fa_data = fa_img.get_fdata()\n",
    "\n",
    "# load MD and get data\n",
    "md_img = nib.load('../data/dmri_examples/MD.nii.gz')\n",
    "md_data = md_img.get_fdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot a slice of FA and MD to visualise what they look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set up plot\n",
    "plt.figure(figsize=(15, 20))\n",
    "\n",
    "# plot FA\n",
    "plt.subplot(1, 2, 1).set_axis_off()\n",
    "plt.imshow(fa_data[:, :, ax_slice], cmap='gray')\n",
    "plt.title(\"FA\")\n",
    "\n",
    "# plot MD\n",
    "plt.subplot(1, 2, 2).set_axis_off()\n",
    "plt.imshow(md_data[:, :, ax_slice], cmap='gray')\n",
    "plt.title(\"MD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional MRI\n",
    "\n",
    "Functional MRI is sensitive to brain activity. More specifically, the rush of blood and oxygen to the area of brain activity. This is called the Blood Oxygen Level Dependent (**BOLD**) response. \n",
    "\n",
    "Again, this is a large topic which we can't cover here. If you'd like to know more, see this blog from the [Royal Society](https://royalsociety.org/blog/2016/08/qa-what-is-bold/) and the [fMRI software carpentry course](https://carpentries-incubator.github.io/SDC-BIDS-fMRI/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of how functional MRI compares to T1w, T2w and diffusion MRI modalities, we will visualise some data without processing it.\n",
    "\n",
    "The data has already been downloaded from a project on OpenNeuro about [adult language learners](https://openneuro.org/datasets/ds003542/versions/1.0.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first lets load the image using the filename we can construct below\n",
    "fmri_filename = local_data_dir + 'fmri_examples/sub-01-func-sub-01_task-compL1_run-1_bold.nii.gz'\n",
    "fmri_image = nib.load(fmri_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's grab the data from the nibabel object again.\n",
    "fmri_data = fmri_image.get_fdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the shape of the fmri data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of functional MRI data also has a 4th dimension (i.e. volumes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(fmri_data[:, :, 15, 0], cmap=\"gray\", origin=\"lower\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the code from the diffusion MRI section, can you visualise the first 4 function MRI volumes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 20))\n",
    "\n",
    "ax_slice = fmri_data.shape[2] // 2;\n",
    "\n",
    "plt.subplot(1, 4, 1).set_axis_off()\n",
    "plt.imshow(fmri_data[:,:,ax_slice,0], cmap='gray')\n",
    "plt.title(\"Volume 1\")\n",
    "\n",
    "plt.subplot(1, 4, 2).set_axis_off()\n",
    "plt.imshow(fmri_data[:,:,ax_slice,1], cmap='gray')\n",
    "plt.title(\"Volume 2\")\n",
    "\n",
    "plt.subplot(1, 4, 3).set_axis_off()\n",
    "plt.imshow(fmri_data[:,:,ax_slice,2], cmap='gray')\n",
    "plt.title(\"Volume 3\")\n",
    "\n",
    "plt.subplot(1, 4, 4).set_axis_off()\n",
    "plt.imshow(fmri_data[:,:,ax_slice,3], cmap='gray')\n",
    "plt.title(\"Volume 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fourth dimension (volumes) now represent *time*. We are interested in how brain activity changes over the course of the scan or in response to experimental conditions carefully designed by the researcher.\n",
    "\n",
    "Complex processing is needed to understand the BOLD response in an experimental design. However, we can glimpse the raw data in each voxel using a function from the nilearn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_carpet(fmri_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing BIDS\n",
    "\n",
    "In MRI studies, you may have multiple MRI modalities for each participant. Organising your files can quickly become confusing!\n",
    "\n",
    "The [Brain Imaging Data Structure (BIDS)](https://www.nature.com/articles/sdata201644) is a simple and intuitive way to organize and describe your neuroimaging and behavioural data. Neuroimaging experiments result in complicated data that can be arranged in several different ways. BIDS tackles this problem by suggesting a new standard (based on consensus from multiple researchers across the world) for the arrangement of neuroimaging datasets. Using the same organizational standard for all of your studies will also allow you to easily reuse your scripts and share data and code with other researchers.\n",
    "\n",
    "For a more comprehensive overview, check out the [BIDS Starter Kit](https://github.com/bids-standard/bids-starter-kit/wiki)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fsdata.2016.44/MediaObjects/41597_2016_Article_BFsdata201644_Fig1_HTML.jpg\" alt=\"Drawing\" align=\"middle\" width=\"600px\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
