{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b267738f",
   "metadata": {},
   "source": [
    "# Quality Control\n",
    "\n",
    "## Objectives\n",
    "- Understand common image artefacts\n",
    "- Visualise processing failures\n",
    "- Explore automatic QC tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062b97e7",
   "metadata": {},
   "source": [
    "### Acquistion\n",
    "#### Due to MR physics (e.g. Field of view (FOV), ghosting, aliasing) \n",
    "Incorrect parameters can truncate and/or duplicate brain anatomy. \n",
    "\n",
    "<img src=\"../fig/MR_physics_QC.png\" alt=\"Drawing\" align=\"middle\" width=\"800px\"/>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a06141b",
   "metadata": {},
   "source": [
    "#### Due to participant (e.g. Motion artifacts) \n",
    "- Participant specific issues such as motion artifcats in Parkinson's patients can manifest in the scan (e.g. ringing effect showing ripples or curved lines).\n",
    "\n",
    "<img src=\"../fig/Motion_QC.png\" alt=\"Drawing\" align=\"middle\" width=\"500px\"/>    \n",
    "\n",
    "#### Due to pathology\n",
    "- Lesions in the brain have a different pixel intensity compared to what is expected. \n",
    "- For example, white matter lesions can appear dark and similiar to grey matter or cerebrospinal fluid.\n",
    "- This can cause errors in the segmentation algorithms that rely on these pixel intensities to classify brain tissues.\n",
    "- [Ozzoude et al. (2020)](https://www.frontiersin.org/articles/10.3389/fnins.2020.598868/full) show how FreeSurfer can either a) over- or b) underestimate cortical grey matter in the presence of white matter lesions.\n",
    "\n",
    "<img src=\"../fig/FS_fails_ozzoude_etal_2020.jpeg\" alt=\"Drawing\" align=\"middle\" width=\"1000px\"/>    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25360f7e",
   "metadata": {},
   "source": [
    "### Quantification\n",
    "Exisiting image processing pipelines (e.g. FreeSurfer, CIVET) will have a few QC tools and examples that can help with failure detection and quality control of volumetric segmentations and surface parcellations.  \n",
    "\n",
    "<img src=\"../fig/Segment_and_surface_QC.png\" alt=\"Drawing\" align=\"middle\" width=\"1000px\"/>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac132cd",
   "metadata": {},
   "source": [
    "It is very important to **visually inspect**:\n",
    "1. Raw MRI data\n",
    "2. Processed MRI data\n",
    "\n",
    "When reporting your results, it is important to state how many images you may have excluded due to image processing failures like those above. Keep track of what you have visually reviewed in a file like a spreadsheet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ab80e1",
   "metadata": {},
   "source": [
    "## Automatic QC tools\n",
    "\n",
    "### Using reports from exisiting pipelines: https://fmriprep.org/en/stable/_static/sample_report.html\n",
    "\n",
    "<img src=\"../fig/sMRIPrep_QC_report.png\" alt=\"Drawing\" align=\"middle\" width=\"700px\"/> \n",
    "\n",
    "\n",
    "### Using QC tools \n",
    "\n",
    "#### [MRIQC](https://github.com/poldracklab/mriqc): extracts no-reference IQMs (image quality metrics) from structural (T1w and T2w) and functional MRI (magnetic resonance imaging) data. _(Developed by the Poldrack Lab at Stanford University for use at the Center for Reproducible Neuroscience (CRN), as well as for open-source software distribution.)_\n",
    "\n",
    "|  Individual report |     Group report        |  \n",
    "| :-------------: | :-----------: |\n",
    "| <img src=\"../fig/mriqc_individual_report.png\" alt=\"Drawing\" align=\"middle\" width=\"700px\"/>  | <img src=\"../fig/mriqc_group_report.png\" alt=\"Drawing\" align=\"middle\" width=\"450px\"/> | \n",
    "\n",
    "\n",
    "#### [VisualQC](https://github.com/raamana/visualqc): assistive tool to improve the quality control workflow of neuroimaging data (Author: Pradeep Reddy Raamana). \n",
    "\n",
    "|  T1w acquisition |     Alignment        | Cortical Parcellation | \n",
    "| :-------------: | :-----------: |:-----------: |\n",
    "| ![t1_mri_visual_QC](../fig/episode_5/t1_mri_visual_QC.png) | ![alignment_mismatched_colormix_visualQC](../fig/alignment_mismatched_colormix_visualQC.png) | ![cortical_zoomed_in](../fig/cortical_zoomed_in.png)| \n",
    "\n",
    "\n",
    "#### [eddyqc](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/eddyqc/UsersGuide): automated quality control tools for diffusion MRI (Author: [Bastiani et al., 2019](https://www.sciencedirect.com/science/article/pii/S1053811918319451?via%3Dihub))\n",
    "\n",
    "<img src=\"../fig/eddyqc.jpeg\" alt=\"Drawing\" align=\"middle\" width=\"700px\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
